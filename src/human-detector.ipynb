{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# reading the frame\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# displaying the frame\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m,frame)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv2.startWindowThread()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # reading the frame\n",
    "    ret, frame = cap.read()\n",
    "    # displaying the frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # breaking the loop if the user types q\n",
    "        # note that the video window must be highlighted!\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# the following is necessary on the mac,\n",
    "# maybe not on other platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2GRAY)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# detect people in the image\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# returns the bounding boxes for the detected objects\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m boxes, weights \u001b[38;5;241m=\u001b[39m \u001b[43mhog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwinStride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m boxes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[x, y, x \u001b[38;5;241m+\u001b[39m w, y \u001b[38;5;241m+\u001b[39m h] \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m boxes])\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (xA, yA, xB, yB) \u001b[38;5;129;01min\u001b[39;00m boxes:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# display the detected boxes in the colour picture\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# open webcam video stream\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# the output will be written to output.avi\n",
    "out = cv2.VideoWriter(\n",
    "    'output.avi',\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    15.,\n",
    "    (640,480))\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    # using a greyscale picture, also for faster detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # detect people in the image\n",
    "    # returns the bounding boxes for the detected objects\n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(8,8) )\n",
    "\n",
    "    boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "\n",
    "    for (xA, yA, xB, yB) in boxes:\n",
    "        # display the detected boxes in the colour picture\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB),\n",
    "                          (0, 255, 0), 2)\n",
    "    \n",
    "    # Write the output video \n",
    "    out.write(frame.astype('uint8'))\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# and release the output\n",
    "out.release()\n",
    "# finally, close the window\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanDetector(args):\n",
    "    image_path = args[\"image\"]\n",
    "    video_path = args['video']\n",
    "    if str(args[\"camera\"]) == 'true' : camera = True \n",
    "    else : camera = False\n",
    "\n",
    "    writer = None\n",
    "    if args['output'] is not None and image_path is None:\n",
    "        writer = cv2.VideoWriter(args['output'],cv2.VideoWriter_fourcc(*'MJPG'), 10, (600,600))\n",
    "\n",
    "    if camera:\n",
    "        print('[INFO] Opening Web Cam.')\n",
    "        detectByCamera(ouput_path,writer)\n",
    "    elif video_path is not None:\n",
    "        print('[INFO] Opening Video from path.')\n",
    "        detectByPathVideo(video_path, writer)\n",
    "    elif image_path is not None:\n",
    "        print('[INFO] Opening Image from path.')\n",
    "        detectByPathImage(image_path, args['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: imutils\n",
      "  Building wheel for imutils (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25872 sha256=428161b7a16dbda5ed6a2f76babf7ed80a42aa8a6759c62bd4533bece1474e98\n",
      "  Stored in directory: /home/anshumaan/.cache/pip/wheels/31/d0/2c/87ce38f6052879e5b7b18f0f8b4a10ad2a9d210e908d449f16\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "    bounding_box_cordinates, weights =  HOGCV.detectMultiScale(frame, winStride = (4, 4), padding = (8, 8), scale = 1.03)\n",
    "    \n",
    "    person = 1\n",
    "    for x,y,w,h in bounding_box_cordinates:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
    "        person += 1\n",
    "    \n",
    "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.imshow('output', frame)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanDetector(args):\n",
    "    image_path = args[\"image\"]\n",
    "    video_path = args['video']\n",
    "    if str(args[\"camera\"]) == 'true' : camera = True \n",
    "    else : camera = False\n",
    "\n",
    "    writer = None\n",
    "    if args['output'] is not None and image_path is None:\n",
    "        writer = cv2.VideoWriter(args['output'],cv2.VideoWriter_fourcc(*'MJPG'), 10, (600,600))\n",
    "\n",
    "    if camera:\n",
    "        print('[INFO] Opening Web Cam.')\n",
    "        detectByCamera(ouput_path,writer)\n",
    "    elif video_path is not None:\n",
    "        print('[INFO] Opening Video from path.')\n",
    "        detectByPathVideo(video_path, writer)\n",
    "    elif image_path is not None:\n",
    "        print('[INFO] Opening Image from path.')\n",
    "        detectByPathImage(image_path, args['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectByCamera(writer):   \n",
    "    video = cv2.VideoCapture(0)\n",
    "    print('Detecting people...')\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "\n",
    "        frame = detect(frame)\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectByPathVideo(path, writer):\n",
    "\n",
    "    video = cv2.VideoCapture(path)\n",
    "    check, frame = video.read()\n",
    "    if check == False:\n",
    "        print('Video Not Found. Please Enter a Valid Path (Full path of Video Should be Provided).')\n",
    "        return\n",
    "\n",
    "    print('Detecting people...')\n",
    "    while video.isOpened():\n",
    "        #check is True if reading was successful \n",
    "        check, frame =  video.read()\n",
    "\n",
    "        if check:\n",
    "            frame = imutils.resize(frame , width=min(800,frame.shape[1]))\n",
    "            frame = detect(frame)\n",
    "            \n",
    "            if writer is not None:\n",
    "                writer.write(frame)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "            if key== ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def detectByCamera(writer):   \n",
    "    video = cv2.VideoCapture(0)\n",
    "    print('Detecting people...')\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "\n",
    "        frame = detect(frame)\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "                break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectByPathImage(path, output_path):\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    image = imutils.resize(image, width = min(800, image.shape[1])) \n",
    "\n",
    "    result_image = detect(image)\n",
    "\n",
    "    if output_path is not None:\n",
    "        cv2.imwrite(output_path, result_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argsParser():\n",
    "    arg_parse = argparse.ArgumentParser()\n",
    "    arg_parse.add_argument(\"-v\", \"--video\", default=None, help=\"path to Video File \")\n",
    "    arg_parse.add_argument(\"-i\", \"--image\", default=None, help=\"path to Image File \")\n",
    "    arg_parse.add_argument(\"-c\", \"--camera\", default=False, help=\"Set true if you want to use the camera.\")\n",
    "    arg_parse.add_argument(\"-o\", \"--output\", type=str, help=\"path to optional output video file\")\n",
    "    args = vars(arg_parse.parse_args())\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v VIDEO] [-i IMAGE] [-c CAMERA]\n",
      "                             [-o OUTPUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/home/anshumaan/.local/share/jupyter/runtime/kernel-v3a91d15cd804b13aaffc757ad6fc289c753135f90.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anshumaan/Development/College/prodex/lib64/python3.11/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    HOGCV = cv2.HOGDescriptor()\n",
    "    HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    args = argsParser()\n",
    "    humanDetector(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prodex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
